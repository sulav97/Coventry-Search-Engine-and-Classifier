MODEL SELECTION COMPARISON MATRIX
================================================================================

Dataset: 114 news documents (Business, Entertainment, Health)
Vectorization: TF-IDF with unigrams/bigrams, 1000 max features
Evaluation: 75/25 train/test split + 5-fold cross-validation

--------------------------------------------------------------------------------
Model                  | Accuracy | Precision | Recall | F1-Score | CV Mean | CV Std
--------------------------------------------------------------------------------
Linear SVM             |    93.1% |     93.3% |  93.3% |    93.3% |   78.9% | ± 7.5% *
Naive Bayes            |    89.7% |     92.3% |  89.3% |    89.7% |   77.2% | ± 4.2%
Logistic Regression    |    82.8% |     85.6% |  82.2% |    82.5% |   78.1% | ± 7.3%
K-Nearest Neighbors    |    79.3% |     80.1% |  79.3% |    79.3% |   78.9% | ± 6.6%
Decision Tree          |    65.5% |     69.7% |  64.4% |    63.0% |   61.3% | ± 9.4%
Random Forest          |    55.2% |     81.2% |  53.7% |    49.1% |   63.0% | ±11.7%
--------------------------------------------------------------------------------

* SELECTED MODEL: Linear SVM

JUSTIFICATION:
- Linear SVM achieves the highest F1-Score (93.3%)
- Good balance between precision and recall across all classes
- Fast training and prediction time
- Works well with TF-IDF features for text classification
- Low cross-validation variance indicates stable performance
